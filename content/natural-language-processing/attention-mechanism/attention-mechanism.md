# 注意力机制

* [返回顶层目录](../../SUMMARY.md#目录)



**经典篇：《Neural Machine Translation by Jointly Learning to Align and Translate》**     

Attention机制最初由图像处理领域提出，后来被引入到NLP领域用于解决机器翻译的问题，使得机器翻译的效果得到了显著的提升。attention是近几年NLP领域最重要的亮点之一，后续的Transformer和Bert都是基于attention机制。



[注意力机制（Attention Mechanism）](https://blog.csdn.net/yimingsilence/article/details/79208092)



[动画图解Attention机制，让你一看就明白](https://mp.weixin.qq.com/s/-XJeyK6OvjAjDOcpXE7olQ)



[真正的完全图解Seq2Seq Attention模型](https://zhuanlan.zhihu.com/p/40920384?utm_source=wechat_session&utm_medium=social&utm_oi=903049909593317376)

[Attention机制详解（一）——Seq2Seq中的Attention](https://zhuanlan.zhihu.com/p/47063917?utm_source=wechat_session&utm_medium=social&utm_oi=903049909593317376)

[计算机视觉中attention机制的理解](https://zhuanlan.zhihu.com/p/61440116?utm_source=wechat_session&utm_medium=social&utm_oi=903049909593317376)

[Attention！注意力机制模型最新综述（附下载）](https://mp.weixin.qq.com/s/CrxbmG7mbsmERMLEDkGYxw)

