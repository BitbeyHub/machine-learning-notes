# ANN人工神经网络

* [返回顶层目录](../../SUMMARY.md#目录)



神经网络为什么可以（理论上）拟合任何函数？

<https://www.zhihu.com/question/268384579>



# 激活函数



[理解神经网络的激活函数](https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247483977&idx=1&sn=401b211bf72bc70f733d6ac90f7352cc&chksm=fdb69fdecac116c81aad9e5adae42142d67f50258106f501af07dc651d2c1473c52fad8678c3&mpshare=1&scene=1&srcid=0508JKgf4ThI1pfcRQSyK3Q4#rd)



卷积网络的激活函数sigmod和relu有什么区别？

使用sigmod函数会导致将近一半的神经元被激活。不太符合人类脑活动工程学。
而relu函数在这方面神似，自动引入稀疏性，相当于无监督预练习。



[理解神经网络的激活函数](http://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247483977&idx=1&sn=401b211bf72bc70f733d6ac90f7352cc&chksm=fdb69fdecac116c81aad9e5adae42142d67f50258106f501af07dc651d2c1473c52fad8678c3&mpshare=1&scene=1&srcid=07308RapV3KncGG6CBZwmF8w#rd)

[神经网络的激活函数总结](https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&mid=2247485762&idx=1&sn=e1e9fc75b92999177d3c61c655b0e06e&chksm=fdb694d5cac11dc37dac1a7ce32150836d66f0012f35a7e04e3dceaf626b8453dc39ee80172b&scene=0#rd)

[一种新的思路通俗理解激活函数](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247488052&idx=1&sn=327b04f1a7b2a7cd62a5c369e33b9f62&chksm=ebb42ae0dcc3a3f6809ba19dfd4432b4700f52a6ca5d448a98e0b6ea58f6a67e41d517295079&mpshare=1&scene=1&srcid=0723FSI6mqiC7zFLQNzK9HpT#rd)

[理解激活函数作用，看这篇文章就够了！](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247488049&idx=1&sn=4cad0db659391faaa4dac0ace524a21f&chksm=ebb42ae5dcc3a3f3145c70529bb828ebdb66429cc0c1433ad5ad5072ef2c2bb86094f27320be&scene=0#rd)

[通俗理解神经网络中激活函数作用](http://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247486431&idx=1&sn=f8f6f1ca8e4ab16616ee5ac853803d3b&chksm=ebb4330bdcc3ba1dc946df1078c49f8e42fe5701afefa8d886d2ca6654698fb9b2c8e0908341&scene=0#rd)



